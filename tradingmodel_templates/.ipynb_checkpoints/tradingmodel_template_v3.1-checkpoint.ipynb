{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79472b27-1278-424c-926c-d7d8d0ec550c",
   "metadata": {},
   "source": [
    "## crypto trading model template v3\n",
    "- 1: Data Loading\n",
    "- 2: Feature Engineering\n",
    "- 3: Data Cleaning\n",
    "- 4: Class Balancing\n",
    "- 5: Feature Scaling\n",
    "- 6: Model Training\n",
    "- 7: Model Evaluation\n",
    "- 8: Cross-Validation\n",
    "#### Future Uses\n",
    "- Hyperparameter Tuning\n",
    "    - Add improved searches to optimize model here\n",
    "- Model Comparisons\n",
    "    - Framework is modular for seamless model swapping\n",
    "- Extended Feature Engineering\n",
    "    - Feature Engineering is endless\n",
    "    - As the the model learns, I gain new insights and expand my field knowledge\n",
    "      - This process is progressive and eventually we'll have a whole system build using this template\n",
    "- Implement paper trading to provide evidence and data for the project cause that would be cool!\n",
    "#### v3 updates\n",
    "- Multi-Timeframe Integration (inprogress)\n",
    "  - fetch data for specific intervals: hourly, four hour, daily, weekly, ...\n",
    "    - increase accuracy of open,close,high,and low values for better feature engineering \n",
    "  - combine and align into comprehensive DataFrame\n",
    "    - combine on features (OHLC) and Volume \n",
    "    - Update Data Cleaning\n",
    "  - Generate Multi-Timeframe Features\n",
    "    - Update indicators for each timeframe: RSI, MACD, MA\n",
    "- Build Feature Iteration Mechanism (in-complete)\n",
    "  - Systematically test combinations of features\n",
    "  - generate heatmaps and visualizations for performance insights\n",
    "  - refine and discard noisy features\n",
    "- Test Models on Improved features\n",
    "  - Evaluate current features without tweaking\n",
    "  - identify how models perform on the baseline setup\n",
    "  - begin planning for presentation here by documenting and comparing each models performance\n",
    "    - this becomes a facet of the project that makes it self analysing, it is self optimizing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe15bb-4d41-4e1c-9520-738c80afae09",
   "metadata": {},
   "source": [
    "### 1: Data Loading\n",
    "- (get_historical_data): Easily swap out the data source or adjust parameters \n",
    "like coin_id, vs_currency, and days for different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2f9c2ca9-80d6-4ec7-86d3-774627a221d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a40fb-ab58-465d-9d7e-20982f0d86a3",
   "metadata": {},
   "source": [
    "### Automated data pull (V3 Update: implement new functions for data retrieval on Multiple Timeframe intervals)\n",
    "- Download cryptocurrency data from a default URL and save as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6a10cbb2-32f2-4034-9142-b886e01ddcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized function to download cryptocurrency data and save as a CSV\n",
    "# Args: output_path (str): Path to save the downloaded CSV\n",
    "     #  url (str): The URL to fetch the CSV data from\n",
    "# Returns: pd.DataFrame: A DataFrame containing the data\n",
    "def download_crypto_data(output_path, url):\n",
    "    \n",
    "    try:\n",
    "        print(f\"Downloading data from {url}\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Save the CSV content\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(response.text)\n",
    "        \n",
    "        print(f\"Data downloaded and saved to {output_path}\")\n",
    "        return pd.read_csv(output_path, skiprows=1)  # Assuming the first row is metadata\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "13e1b15a-fd98-4a06-8ed4-4366e97935a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Downloads cryptocurrency data for a given interval and saves it to a file.\n",
    "# Args:# interval (str): Timeframe interval (e.g., \"1h\", \"4h\", \"d\", \"w\").\n",
    "       # symbol (str): Trading pair symbol (default: BTCUSDT).\n",
    "       # output_dir (str): Directory to save the downloaded CSV.\n",
    "# Returns: pd.DataFrame: A DataFrame containing the data.\n",
    "def download_timeframe_data(interval, symbol=\"BTCUSDT\", output_dir=\"data\"):\n",
    "    import os\n",
    "    \n",
    "    # Define the base URL for CryptoDataDownload\n",
    "    base_url = \"https://www.cryptodatadownload.com/cdd/\"\n",
    "    \n",
    "    # Construct the URL dynamically\n",
    "    url = f\"{base_url}Binance_{symbol}_{interval}.csv\"\n",
    "    output_path = os.path.join(output_dir, f\"{symbol}_{interval}.csv\")\n",
    "    \n",
    "    return download_crypto_data(output_path, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1834a6-4a14-4b30-b4bf-ca72dc9f294f",
   "metadata": {},
   "source": [
    "##### download data for 1h,4h,d,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e410e410-8a22-46ec-a623-a91de7da4c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://api.cryptodatadownload.com/v1/data/OHLC/BINANCE/SPOT\n",
      "Error downloading data: 404 Client Error: Not Found for url: https://api.cryptodatadownload.com/v1/data/OHLC/BINANCE/SPOT\n"
     ]
    }
   ],
   "source": [
    "# Download hourly data\n",
    "hourly_data = download_timeframe_data(interval=\"1h\", symbol = \"BTCUSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "093caea8-a171-42b4-bee5-0120741de41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://api.cryptodatadownload.com/v1/data/OHLC/BINANCE/SPOT\n",
      "Error downloading data: 404 Client Error: Not Found for url: https://api.cryptodatadownload.com/v1/data/OHLC/BINANCE/SPOT\n"
     ]
    }
   ],
   "source": [
    "# Download 4-hour data\n",
    "four_hour_data = download_timeframe_data(interval=\"4h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "065a23f3-1623-4933-814a-db7177c2ce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://api.cryptodatadownload.com/v1/data/OHLC/BINANCE/SPOT\n",
      "Error downloading data: 404 Client Error: Not Found for url: https://api.cryptodatadownload.com/v1/data/OHLC/BINANCE/SPOT\n"
     ]
    }
   ],
   "source": [
    "# Download daily data\n",
    "daily_data = download_timeframe_data(interval=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5859e95e-5231-4e9b-a6a6-f956fa8e2903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://api.cryptodatadownload.com/v1/data/OHLC/BINANCE/SPOT\n",
      "Error downloading data: 404 Client Error: Not Found for url: https://api.cryptodatadownload.com/v1/data/OHLC/BINANCE/SPOT\n"
     ]
    }
   ],
   "source": [
    "# Download weekly data\n",
    "weekly_data = download_timeframe_data(interval=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e67dc-bae7-4e86-aae3-440280bb5bf4",
   "metadata": {},
   "source": [
    "# We hit a limit with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9a6ef-76c1-4628-aca5-19ae7930da14",
   "metadata": {},
   "source": [
    "#### Data Load\n",
    "- Load cryptocurrency data from CSV file\n",
    "- Args:\n",
    "    - fileopath (str): path to CSV file\n",
    "- Returns:\n",
    "    - pd.DataFrame: data loaded into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "46dd1a12-a4d5-4700-9c03-6a0c8e6d8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Crypto Data from CSV\n",
    "def load_crypto_data(filepath):\n",
    "    try:\n",
    "        # Skip the first row and load the data\n",
    "        df = pd.read_csv(filepath, skiprows=1)\n",
    "        print(f\"Data loaded successfully: {len(df)} rows\")\n",
    "        print(\"Column names:\", df.columns)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff4b52-b148-4bb4-8363-a110260fd9f1",
   "metadata": {},
   "source": [
    "### 2: Feature Engineering\n",
    "- (generate_features): Add, remove, or tweak features.\n",
    "- Append more calculations or move them around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d9225638-ca4b-441a-a3c0-fca62b26a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Relative Strength Index (RSI).\n",
    "def rsi(data, window=14):\n",
    "    delta = data['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "18ffaa07-934c-4af6-99f2-461de49b63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: 50-period Moving Average (SMA)\n",
    "def moving_average(data, window=50):\n",
    "    return data['Close'].rolling(window=window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "85b0651d-615b-4502-8ab4-7a79b7fa8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature: MACD (Moving Average Convergence Divergence)\n",
    "def macd(data, short_window=12, long_window=26, signal_window=9):\n",
    "    short_ema = data['Close'].ewm(span=short_window, min_periods=1).mean()\n",
    "    long_ema = data['Close'].ewm(span=long_window, min_periods=1).mean()\n",
    "    macd_line = short_ema - long_ema\n",
    "    signal_line = macd_line.ewm(span=signal_window, min_periods=1).mean()\n",
    "    return macd_line, signal_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8e9c5ec8-21f5-4b57-9855-d520ca23bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Bollinger Bands.\n",
    "def bollinger_bands(data, window=20):\n",
    "    sma = data['Close'].rolling(window=window).mean()\n",
    "    std = data['Close'].rolling(window=window).std()\n",
    "    upper_band = sma + (2 * std)\n",
    "    lower_band = sma - (2 * std)\n",
    "    return upper_band, lower_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "aaf93d2d-24e6-46d2-80ca-15f9ffb2f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Average True Range (ATR).\n",
    "def average_true_range(data, window=14):\n",
    "    high_low = data['High'] - data['Low']\n",
    "    high_close = abs(data['High'] - data['Close'].shift())\n",
    "    low_close = abs(data['Low'] - data['Close'].shift())\n",
    "    tr = high_low.combine(high_close, max).combine(low_close, max)\n",
    "    return tr.rolling(window=window).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a34e9-344e-4575-b24d-9d076e74311e",
   "metadata": {},
   "source": [
    "#### 3: Data Cleaning\n",
    "- (dropna): Handle any future missing data or NaNs, ensures the model doesn't encounter issues when scaling or fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b05cc31d-1023-436b-a26c-5a12e4c603f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataset by handling missing values and scaling features.\n",
    "def clean_data(df):\n",
    "    # Drop rows with NaN values for the required features\n",
    "    df.dropna(subset=['RSI', 'MACD', 'MACD_Signal', '50_MA', 'Upper_Band', 'Lower_Band', 'ATR'], inplace=True)\n",
    "\n",
    "    # Scale numerical features (excluding Upper_Band and Lower_Band)\n",
    "    scaler = StandardScaler()\n",
    "    features_to_scale = ['RSI', '50_MA', 'MACD', 'MACD_Signal', 'ATR']\n",
    "    df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "    print(f\"Data cleaned and scaled: {len(df)} rows remaining\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5b1af97e-bf4d-447f-b138-b8c9c7effc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, process, and clean crypto data.\n",
    "# Args: filepath (str): Path to the CSV file.\n",
    "# Returns: pd.DataFrame: Processed and cleaned data.\n",
    "def prepare_data(filepath):\n",
    "    # Load data\n",
    "    data = load_crypto_data(filepath)\n",
    "    print(\"Data after loading:\", data.head() if data is not None else \"None\")\n",
    "    \n",
    "    if data is not None:\n",
    "        # Ensure 'Close', 'High', and 'Low' are numeric\n",
    "        data['Close'] = pd.to_numeric(data['Close'], errors='coerce')\n",
    "        data['High'] = pd.to_numeric(data['High'], errors='coerce')\n",
    "        data['Low'] = pd.to_numeric(data['Low'], errors='coerce')\n",
    "        \n",
    "        # Generate features\n",
    "        data['RSI'] = rsi(data)\n",
    "        data['50_MA'] = moving_average(data)\n",
    "        data['MACD'], data['MACD_Signal'] = macd(data)\n",
    "        data['Upper_Band'], data['Lower_Band'] = bollinger_bands(data)\n",
    "        data['ATR'] = average_true_range(data)\n",
    "        \n",
    "        print(\"Data before cleaning and scaling:\", data.head())\n",
    "        \n",
    "        # Clean data\n",
    "        prepared_data = clean_data(data)\n",
    "        print(\"Data after cleaning:\", prepared_data.head() if prepared_data is not None else \"None\")\n",
    "        return prepared_data\n",
    "    else:\n",
    "        print(\"Data loading failed.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc07543-0600-4fe4-b6e4-1fbdac199e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e318e78b-7f4b-4018-9812-5a998484a479",
   "metadata": {},
   "source": [
    "### TESTDRIVER : Trading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "67b29bfa-b58e-4873-ba6f-5dc8f830756e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'download_crypto_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[256], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrypto_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m downloaded_file \u001b[38;5;241m=\u001b[39m download_crypto_csv(output_path)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m downloaded_file:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(downloaded_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'download_crypto_csv' is not defined"
     ]
    }
   ],
   "source": [
    "output_path = \"crypto_data.csv\"\n",
    "downloaded_file = download_crypto_csv(output_path)\n",
    "if downloaded_file:\n",
    "    with open(downloaded_file, 'r') as f:\n",
    "        for i in range(5):\n",
    "            print(f.readline())\n",
    "\n",
    "    prepared_data = prepare_data(downloaded_file)\n",
    "    print(prepared_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5d23fcbc-5db2-442d-8512-b217396beb62",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepared_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[258], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(prepared_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRSI\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(prepared_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACD_Signal\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(prepared_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_Band\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Band\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepared_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(prepared_data['RSI'].describe())\n",
    "print(prepared_data[['MACD', 'MACD_Signal']].describe())\n",
    "print(prepared_data[['Close', 'Upper_Band', 'Lower_Band']].head())\n",
    "print(prepared_data['ATR'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7219b6d2-6efc-4de9-81b5-15adfd5c7056",
   "metadata": {},
   "source": [
    "#### 4: Class Balancing (SMOTE)\n",
    "- Adjust sampling_strategy to explore ways to address class imbalance.\n",
    "- Experiment with other resampling techniques here in the future when time permits\n",
    "    - like NearMiss or RandomUnderSampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d5cd5b1f-4ae5-4e18-b2f7-4fed3bf66b37",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepared_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[261], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create target column based on price movement \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m prepared_data\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (prepared_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m prepared_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepared_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Create target column based on price movement \n",
    "prepared_data.loc[:, 'target'] = (prepared_data['Close'].shift(-1) > prepared_data['Close']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8f6fe203-af90-47b6-8a64-fc36d45468bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepared_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[263], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Clean The Data \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m prepared_data \u001b[38;5;241m=\u001b[39m prepared_data\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRSI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACD_Signal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50_MA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_Band\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Band\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assess Cleanliness\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(prepared_data\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepared_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Clean The Data \n",
    "prepared_data = prepared_data.dropna(subset=['RSI', 'MACD', 'MACD_Signal', '50_MA', 'Upper_Band', 'Lower_Band', 'ATR', 'target'])\n",
    "\n",
    "# Assess Cleanliness\n",
    "print(prepared_data.head())\n",
    "print(f\"Number of rows in cleaned data: {len(prepared_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0ee8ac7e-ebf3-495f-a75e-bef4834236c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepared_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[265], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Split into features (X) and target (y)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRSI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m50_MA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMACD_Signal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_Band\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Band\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m X \u001b[38;5;241m=\u001b[39m prepared_data\u001b[38;5;241m.\u001b[39mloc[:, feature_columns]\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m prepared_data\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Split into training and testing sets\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepared_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Split into features (X) and target (y)\n",
    "feature_columns = ['RSI', '50_MA', 'MACD', 'MACD_Signal', 'Upper_Band', 'Lower_Band', 'ATR']\n",
    "X = prepared_data.loc[:, feature_columns]\n",
    "y = prepared_data.loc[:, 'target']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "897f3552-11aa-48fe-bd0f-977b615ed003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[267], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check class distribution before applying SMOTE\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# balance is not bad but why not balance it\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass distribution before SMOTE:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_train\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Check class distribution before applying SMOTE\n",
    "# balance is not bad but why not balance it\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6e0def83-c572-4c56-9e83-537e7ede01d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[269], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply SMOTE to perfect the balance in class distribution\u001b[39;00m\n\u001b[1;32m      2\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_train_res, y_train_res \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Check the class distribution after applying SMOTE\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass distribution after SMOTE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train_res\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to perfect the balance in class distribution\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after applying SMOTE\n",
    "print(f\"Class distribution after SMOTE: {y_train_res.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8369390e-a824-445b-9b7d-292bbcc20e8b",
   "metadata": {},
   "source": [
    "#### 5: Feature Scaling\n",
    "- Currently using the StandardScaler\n",
    "    - Can swap to a different scaler here when time permits\n",
    "    - something like: MinMaxScaler or RobustScaler\n",
    "- Scaling optimizes model performance by created consistent ranges in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07381ba2-5bc0-46d2-986f-e3bf6357b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "56e29692-86e8-49be-9d77-d513a9a50c4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit and transform the training data, and transform the test data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train_res)\n\u001b[1;32m      3\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_res' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit and transform the training data, and transform the test data\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5efce4d6-4fc5-488e-8ce6-bf7004f336d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of scaled training data:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Verify the scaled data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst 5 rows of scaled training data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_scaled[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Verify the scaled data\n",
    "print(\"First 5 rows of scaled training data:\")\n",
    "print(X_train_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460bd5d-75d1-4179-a705-37cf4245f1b1",
   "metadata": {},
   "source": [
    "#### 6: Model Training\n",
    "- Select a model and train it\n",
    "- Default model : (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a2757abd-61fb-44b6-b157-e0151fc163c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Model Selection allows swapping models in an out for performance comparisons\n",
    "# args: #  model_name (str): The name of the model to use (e.g., \"random_forest\").\n",
    "        # X_train (np.array): Scaled training features.\n",
    "        # y_train (np.array): Training target labels.\n",
    "        # X_test (np.array): Scaled testing features.\n",
    "# Returns:\n",
    "        # model: Trained model instance.\n",
    "        # y_pred: Predictions on the test set.\n",
    "def train_model(model_name, X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Dynamically select, train, and evaluate a model.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): The name of the model to use (e.g., \"random_forest\").\n",
    "        X_train (np.array): Scaled training features.\n",
    "        y_train (np.array): Training target labels.\n",
    "        X_test (np.array): Scaled testing features.\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained model instance.\n",
    "        y_pred: Predictions on the test set.\n",
    "    \"\"\"\n",
    "    # Define supported models\n",
    "    models = {\n",
    "        \"random_forest\": RandomForestClassifier(random_state=42),\n",
    "        \"logistic_regression\": LogisticRegression(random_state=42),\n",
    "        \"svm\": SVC(random_state=42),\n",
    "    }\n",
    "    \n",
    "    # Validate model_name\n",
    "    if model_name not in models:\n",
    "        raise ValueError(f\"Model '{model_name}' is not supported.\")\n",
    "    \n",
    "    # Get the selected model\n",
    "    model = models[model_name]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"'{model_name}' training complete.\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"First 5 predictions for '{model_name}': {y_pred[:5]}\")\n",
    "    \n",
    "    return model, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e3adca1f-89af-4450-a10e-3c0fbebb64d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_scaled\u001b[38;5;241m.\u001b[39mshape, y_train_res\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape, y_train_res.shape)  # Ensure they match : allll goood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6ad9b1fb-37cf-4b7f-b4a6-92829b899ee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train_res)  \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)  \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirect training successful. First 5 predictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_pred[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train_res)  # Train the model\n",
    "y_pred = model.predict(X_test_scaled)  # Make predictions\n",
    "print(\"Direct training successful. First 5 predictions:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4e36a52d-d6fa-425e-b37c-62bc1398011e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Try other models like \"logistic_regression\" or \"svm\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, y_pred \u001b[38;5;241m=\u001b[39m train_model(model_name, X_train_scaled, y_train_res, X_test_scaled)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = \"random_forest\"  # Try other models like \"logistic_regression\" or \"svm\"\n",
    "model, y_pred = train_model(model_name, X_train_scaled, y_train_res, X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69842f00-b458-44c5-80ce-8154d2d4e022",
   "metadata": {},
   "source": [
    "#### 7: Model Evaluation\n",
    "- Accuracy, classification report, confusion matrix, and ROC curve.\n",
    "- Implement additional/other metrics here\n",
    "    - perhaps precision-recall curve or F1 score analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "032691dc-f8d2-4118-86a0-4181b5472506",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Accuracy, Classification, Confusion.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Accuracy, Classification, Confusion.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71767f5d-dd67-4b14-b496-97b6335978f9",
   "metadata": {},
   "source": [
    "#### 8: Cross-Validation\n",
    "- Get an accurate view of model performance across multiple folds to reduce overfitting and signal noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6358a2c8-d952-4840-97d6-192167fcce45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e069f9f5-0f1f-47a9-ae5a-c8b941c9bb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae14107-1fde-4ad9-8e1e-743b7eb19dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c4661-67b9-47d3-921f-b5394c97a835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46139a5c-d14a-48dc-94a4-ca910c6571d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaec245-6269-4edc-ae95-3424ec5f063d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
