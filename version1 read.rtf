{\rtf1\ansi\ansicpg1252\cocoartf2821
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 version 1: -function to get data from coin gecko aip -verifies data -indicator functions for: RSI, MAs, MACD -visualize indicator application on graph of OHLC bitcoin price data the max span of days we are allowed to pull for free on coingecko. -cleans data post indicator application to account for new NaN values -testRSI to ensure the proper calculation of RSI and notice new NaN values -visualize prior to recleaning -reclean -test MACD and plot -drop new NaNs generated by indicator application -function to generate long signals that defines basic entry and exit signals and adds them to the clean data frame -clean the data frame after generating signals to account for new NaNs -plot the clean and generated signals over price as green and red triangles respectively, including the 50- period MA for reverence to the chart. -Model evaluation 1: logistic regression -add target column to classify winning and losing trades -train test split - init the model, fit the model, predit on the test set, print accuracy score classification report and confusion matrix -Model Evaluation 2: randomforestclassifier -clean data and generate fresh signals and verify it -split the data in features, train test split, predict and print accuracy score, classification, report, and confusion matrix, (some errors something something not in index that worked before but i think its just cause something got fucked up syntactally a previous cleanup effort whichdoesnt need to fix now. -notice not entering on lows or prebreaksouts -write new signal function to include price action signals -figured out what was up before, i was reordering stuff and i put the new signal function below a model that calls on those signals. nice find. -model evaluation 3: random forest classifier on adjusted signals - train test split, init, fit, predict, print evalutatoin metrics and c.matrix. - improved accuracy but low - visualize confusion matrixs and ROC - model is missing upmoves but ROC is slightly above 50% - try implementing grid search - train test split, apply smote now, init random forest with balanced weights and include hyperparameter tuning using GridSearchCV - get the best_estimator_ from the grid_search and make predictions on test set, evaluate metrics and the confusion matrix: all show decrease in accuracy - model evaluation 4: try XGBoost and realize i cant use it right now for some reason and move on - Model evaluatoin 5: try logistic regression again now that we have adjusted data and signals -LogisticRegression, train test split, smote, log reg init, fit, predict, evaluate metrics and matrix, decrease in accuracy -try the RFC, traintest split predict evaluate metrics, improved accuracy 51% - Attempt a standard scalling of features and crossvalidate the accuracy scores to get generalized feature accuracy - scaler standard fit train RFC with cross validation scores - average cross-validation accuracy : 0.43 - feature engineering is working and we have a 51% accuracy which is something. - propose some solutions - generate some new features: new indicator functions to include some divergences, rolling means, lagging prices, combining features, rsi zones, MA crosses, volatility measures, and we even made an ADX - train test split the new model with an RFC and print evaluation metrics - closing notes, moving to new notebook things getting cluttered. goals: better recall for profitable trades without overfitting, improve class recall maintain accuracy, even at the cost of some precision - lack of data, confusion matrixes are TOO SMALL. new data - improve class weights and targets and fine tune features and try new models designeed for crypto. - create modular template for use as a base for new experiments: for each set, load data, implement desired features, fine-tune weights, SMOTE blanace, run models on fresh data. End version 1}